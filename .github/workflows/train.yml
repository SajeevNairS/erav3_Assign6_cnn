name: Train MNIST Model

on: [push]

jobs:
  train:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.8'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    #- name: Run training
    #  run: |
    #    python assign6.py 

    - name: Check parameter count
      run: |
        echo "Checking total parameter count..."
        python3 -c "
        from assign6 import create_model
        import torch
        
        model = create_model()
        total_params = sum(p.numel() for p in model.parameters())
        print(f'Total parameters: {total_params:,}')
        assert total_params < 20000, f'Model has {total_params:,} parameters, exceeding limit of 20,000'
        "
    
    - name: Check Architecture Requirements
      run: |
        echo "Checking model architecture requirements..."
        python3 -c "
        from assign6 import create_model
        import torch
        import torch.nn as nn
        
        model = create_model()
        
        # 1. Check for Batch Normalization
        has_bn = any(isinstance(m, nn.BatchNorm2d) for m in model.modules())
        assert has_bn, 'Model must use Batch Normalization'
        print('✓ Model uses Batch Normalization')
        
        # 2. Check for Dropout
        has_dropout = any(isinstance(m, nn.Dropout) for m in model.modules())
        assert has_dropout, 'Model must use Dropout'
        print('✓ Model uses Dropout')
        
        # 3. Check for GAP or small FC layers
        has_gap = any(isinstance(m, nn.AdaptiveAvgPool2d) for m in model.modules())
        fc_layers = [m for m in model.modules() if isinstance(m, nn.Linear)]
        
        if has_gap:
            print('✓ Model uses Global Average Pooling')
        else:
            # If no GAP, verify FC layers are small
            for fc in fc_layers:
                assert fc.in_features <= 128, f'FC layer input {fc.in_features} too large. Should use GAP or smaller FC layers'
            print('✓ Model uses appropriate FC layer sizes')
        "

    - name: Check Forward Pass
      run: |
        echo "Verifying forward pass..."
        python3 -c "
        from assign6 import create_model
        import torch
        
        model = create_model()
        batch = torch.randn(1, 1, 28, 28)
        output = model(batch)
        
        assert output.shape == (1, 10), f'Expected output shape (1, 10), got {output.shape}'
        print('✓ Forward pass successful with correct output shape')
        "
        
    - name: Summary
      run: |
        echo "=== Architecture Verification Summary ==="
        echo "✓ Parameter count under 20,000"
        echo "✓ Uses Batch Normalization"
        echo "✓ Uses Dropout"
        echo "✓ Uses Global Average Pooling"
        echo "✓ Forward pass verified"
        echo "All checks passed successfully!" 